version: "3.1"

recipe: default.v1

language: es

# ===============================================
# PIPELINE - Procesamiento de Lenguaje Natural
# ===============================================
pipeline:
  # Tokenización básica para español
  - name: WhitespaceTokenizer

  # Características de expresiones regulares (tiempo, fechas, etc.)
  - name: RegexFeaturizer

  # Características léxicas y sintácticas (incluye lookup tables)
  - name: LexicalSyntacticFeaturizer

  # Vectorización de palabras completas
  - name: CountVectorsFeaturizer
    analyzer: word
    min_ngram: 1
    max_ngram: 2

  # Vectorización de caracteres (útil para errores de tipeo)
  - name: CountVectorsFeaturizer
    analyzer: char_wb
    min_ngram: 1
    max_ngram: 4

  # Clasificador principal DIET (Dual Intent Entity Transformer)
  # Es el corazón del NLU - clasifica intenciones y extrae entidades
  - name: DIETClassifier
    epochs: 200 # Incrementar si tienes más datos
    constrain_similarities: true
    model_confidence: softmax
    entity_recognition: true

    # Arquitectura del modelo
    embedding_dimension: 20
    transformer_size: 256

    # Dropout para prevenir overfitting
    drop_rate: 0.2
    drop_rate_attention: 0.2

    # Usar masked language model para mejor comprensión contextual
    use_masked_language_model: true

    # Balanceo de clases si tienes intenciones desbalanceadas
    # batch_strategy: "balanced"

    # Learning rate
    learning_rate: 0.001

  # Mapeo de sinónimos a valores canónicos
  - name: EntitySynonymMapper

  # Response Selector para responder FAQs directamente
  - name: ResponseSelector
    epochs: 100
    retrieval_intent: faq
    constrain_similarities: true

  # Clasificador de fallback para baja confianza
  - name: FallbackClassifier
    threshold: 0.7 # Confianza mínima para aceptar predicción
    ambiguity_threshold: 0.1 # Diferencia mínima entre top 2 intenciones

# ===============================================
# POLICIES - Predicción de siguiente acción
# ===============================================
policies:
  # Memorización de patrones exactos (muy útil para reglas)
  - name: MemoizationPolicy
    max_history: 5 # Cuántos turnos recordar

  # Política basada en reglas (determinística)
  - name: RulePolicy
    core_fallback_threshold: 0.4
    core_fallback_action_name: "action_default_fallback"
    enable_fallback_prediction: true
    restrict_rules: true # Las reglas solo se aplican cuando coinciden exactamente

  # TED Policy - Transformer Embedding Dialogue
  # La política más potente para conversaciones complejas
  - name: TEDPolicy
    max_history: 5
    epochs: 200
    constrain_similarities: true
    model_confidence: softmax

    # Arquitectura del transformer (se usan los valores por defecto para los tamaños)
    embedding_dimension: 20

    # Regularización
    drop_rate: 0.2
    drop_rate_attention: 0.2

    # Learning rate
    learning_rate: 0.001

    # Prevenir predicciones de loops infinitos
    # use_max_loop_count: true
    # max_loop_count: 3

# ===============================================
# CONFIGURACIONES ADICIONALES
# ===============================================
assistant_id: chato-bot
